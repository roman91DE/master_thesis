{ # first presented in Wittenberg, Rothlauf, and Schweim (2020)
 'console_out'    : True,
 'monitor_path'   : '../tmp/monitor.pkl',

 'random_seed'    : 1000,
 'algorithm'      : 'DAE_LSTM',
 'popsize'        : 1000, #500!
 'initialization' : {
                            'mode'          : 'ramped-half-and-half',  # 'grow', 'full',
                            'min_tree_depth': 2,
                            'max_tree_depth': 6,
                    },
 'selection'      : {
                            'type'             : 'none',  # 'random', 'none', 'fitness_proportionate', 'tournament', 'aut_epsilon_lexicase'
                            'tournament_size'  : 7, # only for tournament selection
                    },
 'variation'      : [
                         {
                             'type'                     : 'DAE-LSTM',
                             'saving_directory'         : '../data/keras_model/best_model.h5',
                             'TensorBoard'              : False,
                             'TensorBoard_directory'    : '../data/keras_model/TensorBoard/' + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
                             'batch_size'               : 0.1, # percent of training population
                             'learning_rate'            : 0.001, # 0.001 is default value
                             'hidden_layers'            : 2,  # 3,4,5,6
                             'embedding'                : False, # emb. size is set automatically - set to False if you do not want to use an embedding
                             'training_mode'            : 'fixed_number_of_epochs', # 'fixed_number_of_epochs', 'early_stopping', 'Levenshtein_analysis_first_gen', 'convergence'
                             'max_epochs'               : 1000, # 5000 currently standard
                             'patience'                 : 200, # for early stopping and convergence, no. of epochs that we accept no improvement
                             'min_delta'                : 0.05, # 0.05 before, for early stopping and convergence, minimum change in loss that qualifies for improvement
                             'val_split_ratio'          : 0.5, # only for early stopping, defines the ratio of training data that is used as validation data
                             'sampling_steps'           : 1, # the more sampling steps, the less variation
                             'restr_all_sampling_steps' : False, # if False, we only restrict the last sampling step to valid solution space, no influence when sampling_steps is set to 1
                             'model_input'              : 'sel_pop', # 'init_pop', 'sel_pop', 'random_pop', 'crossover'
                             'corruption_technique'     : 'lev_edit', # 'lev_edit', 'lev_tree_edit'. 'point_mutation',
                             'edit_perc_training'       : 0.05, # for lev_edit, lev_tree_edit, and point_mutation (has to be between 0 and 1)
                             'edit_perc_sampling'       : 0.95, # only for sel_pop
                             'node_bias_terminals'      : 0.1, # only for crossover model input
                         },
                    ],
 'termination'    : {
                            'terminate_when_best_found'      : [False, 0],
                            'terminate_when_no_uniqueness'   : [False, 0.01],
                            'max_fitness_evaluations'        : [False, 10000],
                            'max_generations_no_improvement' : 1,
                            'max_generations'                : 1,
                    },
 'stats'          : {
                            'print_memory_analysis'          : False,
                            'print_runtime_analysis'         : False,
                            'manhattan_dist_output_vector'   : False, # expensive for large pop sizes!
                            'lev_diversity'                  : True, # expensive for large pop sizes!
                            'lev_between_pop'                : False, # expensive for large pop sizes!
                            'input_output_treesize_analysis' : True,
                    },
}
# Hard coded: Max. depth is 17 (recommended by DEAP developers)