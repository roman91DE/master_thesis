---
title: "Pre-Trained Denoising Autoencoders Long Short-Term Memory Networks as probabilistic Models for Estimation of Distribution Genetic Programming"
subtitle: "Kolloquium zur Masterarbeit im M.Sc. Wirtschaftspädagogik "
author: "Roman Hoehn"
institute: "Johannes Gutenberg-Universität Mainz"
date: "Datum: 25.01.2023"
fontsize: 11pt
output:
  beamer_presentation:
    color: "beaver"
    theme: "Szeged"
    #fonttheme: "structurebold"
    fig_width: 12
    fig_height: 10
    # keep_tex: true
    fig_caption: yes
    number_sections: true
    slide_level: 2
toc: yes
bibliography: ref/ref.bib
csl: csl/harvard-cite-them-right.csl
includes:
      in_header: [header_files/slides.tex]
---


```{r setup, include=FALSE}
library(magrittr)
knitr::opts_chunk$set(echo = TRUE)
```



# Einleitung

## Forschungsfrage

*Kann das Suchverhalten der Denoising Autoencoder Genetic Programming (DAE-GP) Metaheuristik durch den Einsatz einer Pre-Training Strategie optimiert werden?*


Welchen Effekt hat Pre-Training auf:

  1. das Generalisierungsverhalten von DAE-GP?
  2. die Qualität der gefundenen Programme (Fitness/Programmlänge)?
  3. die Populationsdiversität?
  4. das Laufzeitverhalten?
  
Anwendungsgebiet: Symbolische Regression, insbesondere am Aifoil Datensatz
  


# Denoising Autoencoder Genetic Programming

## Übersicht

* Metaheuristik basierend auf genetischer Programmierung (GP)
* Erweiterung von GP durch künstliche, neuronalen Netzen zur Optimierung des Suchverhaltens
* Variante des Estimation of Distribution-GP (EDA-GP)


## Estimation of Distribution Algorithmen (EDA)

* Entwicklung neuer Rekombinationsoperatoren für evolutionäre Algorithmen basierend auf dem Einsatz von probabilistischen Modellen^[@design_of_modern_heuristics]
* Hypothese: Problemspezifische Abhängigkeiten zwischen einzelnen Entscheidungsvariablen können bei der Erzeugung neuer Lösungskandidaten besser berücksichtigt werden als bei traditionellen Rekombinationsoperatoren^[@edaOrig1996]
* Weitere Verbreitung im Bereich der genetischen Algorithmen (GA) als für GP

## DAE-EDA

Idee: Einsatz von Denoising Autoencoders (DAE) als probabilistisches Modell für EDA [@harmless_overfitting_eda]

2 Phase Ansatz:

  1. Model Building: Modell "lernt" die Eigenschaften von ausgewählten Lösungen hoher Güte
  2. Model Sampling: Neue Lösungen werden erzeugt durch das propagieren von bestehenden, mutierten Lösungen durch das erlernte Modell 
  

## DAE-GP



# Aktueller Forschungsstand

## Generalisiertes Royal Tree Problem (GRT)^[@dae-gp_2020_rtree]:

  * Einfaches Suchproblem mit hoher Lokalität
  * DAE-GP erzeugt durch Model Sampling Lösungskandidaten mit höherer Fitness als GP 
  * Hohe Güte der erzeugten Lösungskandidaten resultiert in besserer Performance
  * Perfomance Vorteil steigt mit zunehmender Komplexität des GRT Problems
  
  
## Symbolische Regression^[@dae-gp_2022_symreg]:

  * Airfoil Datensatz für Real-World symbolische Regression
  * DAE-GP erzeugt für eine vorgegebene Anzahl von Fitness Evaluationen im Vergleich zu GP:
  
    1. Lösungen mit höherer Fitness
    2. Lösungen  mit geringerer Größe
    

  



## Pre-Training

## Implementation

# Experimente

## Symbolische Regression

## Generalisierungsverhalten

## Lösungsqualität

# Resultate

# Weitere Ansätze


# References {.allowframebreaks} 







